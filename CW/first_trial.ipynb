{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "718e93ae-219d-44a4-a6a1-938bda3dedb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e30d5ba-cb54-4659-941e-c4b2b0d785c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functionalities\n",
    "import visionNew\n",
    "from Utilities.metrics import pixelwiseAccuracy\n",
    "from Utilities.datasetHandler import CityscapesDataset\n",
    "from Utilities.modelHandler import modelFCN\n",
    "\n",
    "import torch\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from torchvision.models.segmentation import fcn_resnet50, FCN_ResNet50_Weights\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available(): device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d04553-c49e-4a4e-948f-c80bb23d759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATASET ###\n",
    "\n",
    "# Read single image\n",
    "dtTEST = CityscapesDataset(image_directory=\"TestPascal\", phase=None, num_classes=21)\n",
    "img = dtTEST.get_image_path(\"2011_003182.jpg\")\n",
    "\n",
    "\n",
    "# Handle real dataset\n",
    "dt = CityscapesDataset(image_directory = '/mnt/data/course/psarin/inm705/pascal_voc_2012',\n",
    "                       gt_directory = '/mnt/data/course/psarin/inm705/pascal_voc_2012/GT',\n",
    "                       label_directory = '/mnt/data/course/psarin/inm705/pascal_voc_2012/annotations',\n",
    "                       phase = 'train',\n",
    "                       num_classes= 21)\n",
    "\n",
    "# Pascal VOC categories\n",
    "object_categories = ['aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                     'bottle', 'bus', 'car', 'cat', 'chair',\n",
    "                      'cow', 'diningtable', 'dog', 'horse',\n",
    "                      'motorbike', 'person', 'pottedplant',\n",
    "                     'sheep', 'sofa', 'train', 'tvmonitor']\n",
    "#weights.meta[\"categories\"]\n",
    "\n",
    "\n",
    "# convert list to dict\n",
    "pascal_voc_classes = {}\n",
    "for id, name in enumerate(object_categories): \n",
    "    pascal_voc_classes[name]=id # these are the same indices used to create the label vector y in the dataset \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efae0a8c-9ade-4e00-9376-1af109c6c65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL Pretrained with RESNET 50\n",
    "# Initialize model with the best available weights\n",
    "FCN_weights = FCN_ResNet50_Weights.DEFAULT\n",
    "backbone_weights = ResNet50_Weights.DEFAULT\n",
    "model = fcn_resnet50(backbone_weights=backbone_weights).to(device)\n",
    "model.eval()\n",
    "\n",
    "batch = img.unsqueeze(0).to(device)\n",
    "\n",
    "dataloader_args = {'batch_size':100, 'shuffle':False}\n",
    "testloader = DataLoader(dt, **dataloader_args) # dataloader adds the B dimension to CxHxW input image, the number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "503887c4-273b-448c-9e0d-d16623b7445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cel = CrossEntropyLoss()\n",
    "ad = Adam(model.parameters())\n",
    "\n",
    "fcn1 = modelFCN(model, loss_function=cel, optimizer = ad )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8827c712-5a6d-4f02-9e50-cb8b8c0aeaa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.37 GiB (GPU 0; 79.35 GiB total capacity; 76.27 GiB already allocated; 705.19 MiB free; 77.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_120153/710208987.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/INM705/CW/Utilities/modelHandler.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(self, dataloader, total_epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.37 GiB (GPU 0; 79.35 GiB total capacity; 76.27 GiB already allocated; 705.19 MiB free; 77.12 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "L = fcn1.train_model(testloader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fdf5b50-f58d-4153-8090-4d81e6e781a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Use the model and visualize the prediction\n",
    "pred = model(batch)['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f88a77b-c907-488c-b876-50cd7435108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idd, X, y = next(iter(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bf23c0d-b2d1-4958-8a39-853ee29a82d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 21, 350, 500])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1aa69-f78c-473e-9f33-8bb8f995c59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ce58ec6-6771-453e-a746-b2c5cec99ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2643, device='cuda:0', grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = X.to(device), y.to(device)\n",
    "cel(model(X)['out'],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec1ac1-d210-46ce-bed4-e9f30a97b24e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3e81d-d2ba-4db1-8723-e46878493142",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "551b0568-3b9e-4b71-a0c7-7a20e2fd7e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21, 350, 500])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc732e46-2e36-455a-bcf2-d1c3166618ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89482b6-76c2-4fe8-8f55-bbd3250bddee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da27ad92-ef03-434e-931b-f66205aa0d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4ab5f-ee4d-4627-96f5-2b2b156445a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "722d54d1-1859-46b6-9602-bc80b598066e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "n_classes = 21\n",
    "g = gg.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20b337ae-7bed-439f-9b85-63afcee355d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.Tensor([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ec71b129-cc6c-4145-b4c1-dad4cee1cf4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "efc8de6b-b149-4bf2-ac0c-acca677f37e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0],\n",
      "        [0, 0]])\n",
      "tensor([[1, 0],\n",
      "        [0, 0]])\n",
      "tensor([[0, 1],\n",
      "        [0, 0]])\n",
      "tensor([[0, 0],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f763264-0c18-403c-b6dc-974cc9e542d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0],\n",
       "        [0, 0]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test==1)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542578dd-c106-4bd0-a5c3-3564e28e6c31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a19ea82a-3c3a-4176-8e71-6fd64be36b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 350, 500)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d01809f-cbd5-4069-906e-0944bd268c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.zeros((n_classes,350,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d2a56f49-02c4-4834-af76-37cd2c995c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,nn in enumerate(n):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7625f-f923-45c9-a420-292dfc397c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = torch.Tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e876f489-ef46-4ab8-bc37-043dc5c15b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f192021-eefa-4ad7-bf34-c3a453bf015f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab50c6d-ab51-4da9-83d8-bfe4077af84c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fa778-e566-4c95-a80b-ec18e71ee1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52324d-8710-425d-824b-5aa273b75a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac599c-bda4-47fb-9249-315a7ff9586e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a1ae66-3c9c-4346-b8c7-f28ba5a05b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce90fd31-e09c-4206-953c-4a3b7826f422",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ce976-00ee-4644-9c81-ae153cea9052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc025b-36b8-4688-ad82-f87e2fa6c314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7989c31-19c9-4412-a998-f5e950ed31bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f51bad-2a5f-4df2-9a65-1aefe64e20d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'aux'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_119601/1613747075.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpred_aux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"aux\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'aux'"
     ]
    }
   ],
   "source": [
    "# Step 4: Use the model and visualize the prediction\n",
    "pred = model(batch)\n",
    "\n",
    "prediction = pred[\"out\"]\n",
    "pred_aux = pred[\"aux\"]\n",
    "\n",
    "\n",
    "normalized_masks = prediction.softmax(dim=1)\n",
    "normalized_aux = pred_aux.softmax(dim=1)\n",
    "\n",
    "# Indices of classes\n",
    "class_to_idx = {cls: idx for (idx, cls) in enumerate(weights.meta[\"categories\"])}\n",
    "\n",
    "n_lab = 2\n",
    "\n",
    "\n",
    "mask = normalized_masks[0, class_to_idx[\"sofa\"]] #+ normalized_masks[0, class_to_idx[\"horse\"]]\n",
    "to_pil_image(mask)\n",
    "\n",
    "#print(mask.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5dad5-9e1e-49ab-b653-7feb55c219ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import ground truth \n",
    "gt = read_image(\"TestPascal/2011_003182.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eef9b1-a05d-4b4f-96c0-007a8e7de7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixelwiseAccuracy(prediction,gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33a0767-06df-451c-8efc-f9781a0012e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ae2f5-c073-4ae3-aa11-ed5123637d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "\n",
    "name = 'TestPascal/2007_000032.xml'  \n",
    "with open(name, 'r') as f:\n",
    "    html_string = f.read()\n",
    "soup = BeautifulSoup(html_string, 'html.parser')\n",
    "labels = []\n",
    "area = []\n",
    "\n",
    "while soup.object is not None:\n",
    "    obj = soup.object.extract()\n",
    "    obj_name = obj.find('name').get_text()\n",
    "    labels.append(pascal_voc_classes.get(obj_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eae47d-99e4-43d8-b638-317841c0e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546b479e-af36-484d-994a-eabc2ae72796",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf63503-ccc1-4448-9a78-321a5febfe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utilities.torchsummaryNew import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefd8e55-1e2c-4353-946f-acba927b9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675ad56-e464-4a47-b32b-25806a8590bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1, 3, 224, 224).to(device)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcb1816-6203-428c-8555-635e545a1fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf0b66-740c-49ae-bc83-588f39d6382b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
